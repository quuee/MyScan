# infer.py æ¨ç†
import torch
from PIL import Image
import torchvision.transforms as T
from unet import UNet
import os

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "./unet/checkpoints/unet_denoise_rgb.pth"
IMAGE_SIZE = 512

# åŠ è½½æ¨¡å‹
model = UNet(in_channels=3, out_channels=3).to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.eval()

# è¯»å›¾
input_path = "./unet/test_img/0002.jpg"  # æ”¹æˆä½ çš„æµ‹è¯•å›¾
original_img = Image.open(input_path).convert("RGB")
orig_size = original_img.size

# é¢„å¤„ç†
transform = T.Compose([
    T.Resize((IMAGE_SIZE, IMAGE_SIZE), interpolation=T.InterpolationMode.BILINEAR),
    T.ToTensor()  # [0,1]
])
to_pil = T.ToPILImage()

input_tensor = transform(original_img).unsqueeze(0).to(DEVICE)  # [1,3,512,512]

with torch.no_grad():
    output_tensor = model(input_tensor)
    output_tensor = torch.clamp(output_tensor, 0, 1)  # å¿…é¡»ï¼

    # ğŸ”¥ å…³é”®è°ƒè¯•ï¼šæ‰“å°è¾“å‡ºå¼ é‡ä¿¡æ¯
    print("\nğŸ” æ¨ç†è¾“å‡ºå¼ é‡åˆ†æ:")
    print(f"  shape: {output_tensor.shape}")
    print(f"  min: {output_tensor.min().item():.6f}")
    print(f"  max: {output_tensor.max().item():.6f}")
    print(f"  mean: {output_tensor.mean().item():.6f}")
    print(f"  std: {output_tensor.std().item():.6f}")
    print(f"  NaN: {torch.isnan(output_tensor).any().item()}")
    print(f"  Inf: {torch.isinf(output_tensor).any().item()}")

    # å®‰å…¨å¤„ç†
    if torch.isnan(output_tensor).any():
        print("âš ï¸ æ£€æµ‹åˆ° NaNï¼Œç”¨é›¶å¡«å……")
        output_tensor = torch.zeros_like(output_tensor)
    if torch.isinf(output_tensor).any():
        print("âš ï¸ æ£€æµ‹åˆ° Infï¼Œè£å‰ª")
        output_tensor = torch.clamp(output_tensor, -10, 10)

    output_tensor = torch.clamp(output_tensor, 0, 1)  # ç¡®ä¿ [0,1]

# è½¬ä¸º PIL å¹¶æ¢å¤åŸå§‹å°ºå¯¸
output_pil = to_pil(output_tensor.cpu().squeeze(0))
output_pil = output_pil.resize(orig_size, Image.BILINEAR)
output_pil.save("./unet/test_img/debug_output.png")
print("\nâœ… å·²ä¿å­˜: debug_output.png")
