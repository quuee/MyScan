# ç»™å¤–éƒ¨ä½¿ç”¨
# denoiser.py
import torch
import numpy as np
from PIL import Image
import torchvision.transforms as T
from unet.unet import UNet

import os


class DocumentDenoiser:
    """
    æ–‡æ¡£å»å™ªå™¨ï¼šè¾“å…¥/è¾“å‡ºå‡ä¸º numpy array
    è¾“å…¥: np.ndarray (H, W, 3), dtype=uint8 [0,255] æˆ– float32 [0,1]
    è¾“å‡º: np.ndarray (H, W, 3), dtype=float32, range [0,1]
    """

    def __init__(self, model_path, img_size=512, device=None):
        self.img_size = img_size
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

        # æ„å»ºæ¨¡å‹
        self.model = UNet(in_channels=3, out_channels=3)
        self.model.to(self.device)
        self.model.eval()

        # åŠ è½½æƒé‡
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        try:
            state_dict = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_path} (device={self.device})")
        except Exception as e:
            raise RuntimeError(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")

        # é¢„å¤„ç† transform
        self.transform = T.Compose([
            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.BILINEAR),
            T.ToTensor(),  # è‡ªåŠ¨å½’ä¸€åŒ–åˆ° [0,1]
        ])

    def _numpy_to_pil(self, image: np.ndarray) -> Image.Image:
        if image.dtype == np.uint8:
            pass
        elif image.dtype in [np.float32, np.float64]:
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = image.astype(np.uint8)  # å‡è®¾å·²ç»æ˜¯ [0,255]
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {image.dtype}")

        return Image.fromarray(image)

    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """
        å°† [1,3,H,W] tensor è½¬ä¸º (H, W, 3) numpy array
        """
        # ç§»é™¤ batch ç»´åº¦å¹¶è½¬åˆ° cpu
        tensor = tensor.squeeze(0).cpu().clamp(0, 1)  # [3,H,W]
        # è½¬ä¸º numpy (H, W, 3)
        array = tensor.permute(1, 2, 0).numpy()  # [H,W,3]
        return array.astype(np.float32)

    @torch.no_grad()
    def denoise(self, image: np.ndarray, resize_to_original=True) -> np.ndarray:
        """
        å¯¹å•å¼  numpy å›¾åƒå»å™ª
        :param image: np.ndarray, shape=(H, W, 3), dtype=uint8 æˆ– float32
        :param resize_to_original: æ˜¯å¦æ¢å¤åŸå§‹å°ºå¯¸
        :return: np.ndarray, shape=(H, W, 3), dtype=float32, range [0,1]
        """
        if not isinstance(image, np.ndarray):
            raise TypeError("è¾“å…¥å¿…é¡»æ˜¯ numpy.ndarray")

        if image.ndim != 3 or image.shape[2] != 3:
            raise ValueError(f"è¾“å…¥å¿…é¡»æ˜¯ (H, W, 3) çš„å›¾åƒï¼Œå½“å‰ shape: {image.shape}")

        original_h, original_w = image.shape[:2]

        # è½¬ä¸º PIL è¿›è¡Œç»Ÿä¸€é¢„å¤„ç†
        pil_image = self._numpy_to_pil(image)

        # é¢„å¤„ç†ï¼šè°ƒæ•´å¤§å° + è½¬ä¸º tensor
        input_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)  # [1,3,512,512]

        # æ¨ç†
        output_tensor = self.model(input_tensor) # [1,3,512,512]
        print(f"ğŸ“Œ æ¨¡å‹åŸå§‹è¾“å‡º: min={output_tensor.min().item():.4f}, "
            f"mean={output_tensor.mean().item():.4f}, max={output_tensor.max().item():.4f}")

        # åå¤„ç†ï¼šè£å‰ªå¼‚å¸¸å€¼
        output_tensor = torch.clamp(output_tensor, 0, 1)

        # è½¬å› numpy
        output_array = self._tensor_to_numpy(output_tensor)  # [H,W,3], float32, [0,1]

        # æ˜¯å¦æ¢å¤åŸå§‹åˆ†è¾¨ç‡ï¼Ÿ
        if resize_to_original and (output_array.shape[0] != original_h or output_array.shape[1] != original_w):
            # ä½¿ç”¨ scipy æˆ– cv2 æ›´é«˜æ•ˆï¼Œè¿™é‡Œç”¨ PIL ç®€å•å®ç°
            pil_out = Image.fromarray((output_array * 255).astype(np.uint8))
            pil_out = pil_out.resize((original_w, original_h), Image.BILINEAR)
            output_array = np.array(pil_out).astype(np.float32) / 255.0  # [H,W,3], float32, [0,1]

        return output_array

    @torch.no_grad()
    def denoise_batch(self, images):
        """
        æ‰¹é‡å»å™ªï¼ˆé€å¼ å¤„ç†ï¼‰
        :param images: list of np.ndarray
        :return: list of np.ndarray
        """
        results = []
        for img in images:
            try:
                result = self.denoise(img)
                results.append(result)
            except Exception as e:
                print(f"âš ï¸ å»å™ªå¤±è´¥: {e}")
                results.append(None)
        return results

    def set_device(self, device):
        self.device = device
        self.model.to(device)
        print(f"ğŸ”§ è®¾å¤‡å·²åˆ‡æ¢è‡³: {device}")
